[
  {
    "question": "이번에 인사팀에서 이력서 검토 시간을 줄이려고 AI 자동 필터링 솔루션을 도입하려고 하는데요. 이거 법적으로 문제 되는 부분 있을까요?",
    "answer": "인사팀에서 이력서 검토를 위해 도입하려는 AI 자동 필터링 솔루션은 고위험 AI로 분류될 가능성이 매우 높습니다. 먼저, 유럽 인공지능법(EU AI Act) 부속서 3에 따르면 채용 및 인사 관리에 직접적으로 관여하는 AI 시스템은 고위험으로 엄격히 규제됩니다. 이는 해당 시스템이 지원자의 서류 탈락 여부를 결정함으로써 개인의 직업적 기회와 생계에 중대한 영향을 미칠 수 있기 때문입니다.\n반면, 한국 인공지능기본법 제2조에 따르면 채용 등 개인의 권리와 의무에 중대한 영향을 미치는 AI는 '고영향 인공지능'에 해당합니다. 이에 따라 해당 시스템을 운영하는 사업자는 제34조에 의거하여 위험 관리 계획을 수립하고 신뢰성을 확보하기 위한 조치를 취해야 할 의무가 발생합니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 해당 AI 시스템을 주로 어느 국가(시장)에서 서비스하실 계획인가요?\n* 이 AI 시스템이 채용 탈락 결정에 직접적이고 최종적인 권한을 가지나요?\n* AI가 분석하는 이력서 데이터에 지원자의 민감 정보(종교, 출신 지역 등)가 포함되어 있나요?\n\n- 규제 대상: 채용 및 인사 관리에 사용되는 고위험 AI 및 고영향 인공지능\n- 핵심 의무: 적합성 평가(EU), 신뢰성 확보 및 위험 관리 계획 수립(한국)\n- 위반 리스크: 고위험 AI 규제 위반에 따른 법적 제재 및 차별 논란\n- 근거 조항: 유럽 인공지능법(EU AI Act) 부속서 3, 한국 인공지능기본법 제2조, 제34조"
  },
  {
    "question": "한국 인공지능기본법에서 말하는 '고영향 AI' 기준이랑, 유럽 AI Act의 고위험 AI 기준이 어떻게 연결돼? 한국에서 서비스할 때 유럽 법안의 어떤 부분을 보완해서 참고해야 할까?",
    "answer": "한국 인공지능기본법의 '고영향 AI'와 유럽 AI Act의 '고위험 AI'는 모두 AI 시스템이 인간의 기본권과 생계에 미치는 중대한 영향을 기준으로 규제 대상을 설정한다는 점에서 깊이 연결되어 있습니다. 한국 인공지능기본법 제2조에서는 채용, 대출 등 개인의 권리와 의무에 중대한 영향을 미치는 시스템을 '고영향 인공지능'으로 정의하며, 제34조를 통해 해당 사업자에게 위험 관리 및 신뢰성 확보 의무를 부과하고 있습니다. 반면, 유럽 인공지능법(EU AI Act) 제6조 및 부속서 3은 채용, 의료 등 특정 분야를 명시적으로 고위험으로 분류하여 엄격한 적합성 평가를 요구합니다.\n따라서 한국에서 서비스를 제공하더라도 향후 글로벌 확장을 고려한다면, 한국법의 제2조 및 제34조에 따른 기본적 의무에 더해 EU AI Act의 세밀한 고위험 분류 기준과 강력한 사전 적합성 평가 절차를 보완적으로 참고하여 선제적인 위험 관리 체계를 구축해야 합니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 현재 기획 중인 AI 서비스가 주로 어떤 산업 분야(예: 금융, 의료, 인사 등)에서 활용될 예정인가요?\n* 추후 유럽 시장으로 서비스를 확장하거나 유럽 거주자의 데이터를 처리할 계획이 있나요?\n\n- 규제 대상: 한국 인공지능기본법의 고영향 인공지능 및 유럽 AI Act의 고위험 AI 시스템\n- 핵심 의무: 위험 관리 계획 수립(한국) 및 제3자 적합성 평가(유럽)\n- 위반 리스크: 각 법안에 명시된 규제 미준수에 따른 행정적 제재 및 시장 출시 제한\n- 근거 조항: 한국 인공지능기본법 제2조, 제34조, 유럽 인공지능법(EU AI Act) 제6조 및 부속서 3"
  },
  {
    "question": "유럽 지사 채용 과정에서 지원자의 표정과 목소리 톤을 분석해서 스트레스 저항성을 평가하는 AI 면접 툴을 전면 도입하려고 합니다. 위반 시 페널티와 미리 준비해야 할 사항이 궁금합니다.",
    "answer": "유럽 지사 채용 과정에서 지원자의 표정과 목소리 톤을 분석해 감정을 추론하는 AI 면접 툴의 도입은 원칙적으로 전면 금지되는 행위입니다. 유럽 인공지능법(EU AI Act) 제5조에 따르면 직장 내에서 생체 인식 및 감정 인식을 사용하는 것은 지원자의 기본권을 심각하게 침해하는 것으로 간주됩니다. 만약 이를 강행하여 금지 조항을 위반할 경우, 제71조에 따라 최대 3,500만 유로 또는 전 세계 매출의 7% 중 더 높은 금액이 과징금으로 부과되는 치명적인 리스크가 발생합니다. 따라서 해당 프로젝트는 전면 재검토가 필요하며, 감정 인식이 아닌 단순 역량 평가 AI로 선회하더라도 제14조의 인적 감독 의무를 필수적으로 준수해야 합니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 해당 AI 툴의 도입 목적을 감정 추론이 아닌 단순 직무 역량(언어 구사력 등) 평가로 변경할 여지가 있나요?\n* 시스템에서 수집하는 음성 및 영상 데이터의 보관 주기나 파기 방식은 어떻게 설계되어 있나요?\n\n- 규제 대상: 직장 내 감정을 추론하는 생체 인식 및 감정 인식 AI\n- 핵심 의무: 금지된 AI 관행 중단 및 고위험 AI 전환 시 인적 감독 의무 준수\n- 위반 리스크: 최대 3,500만 유로 또는 전 세계 매출의 7% 과징금 부과\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제5조, 제14조, 제71조"
  },
  {
    "question": "내부 인트라넷 활동 로그와 메신저 접속 시간을 데이터로 활용해서 퇴사 고위험군 직원을 예측하는 AI 모델을 자체 개발 중입니다. 데이터 수집과 활용 면에서 준수해야 할 법적 가이드라인이 있나요?",
    "answer": "직원의 사내망 활동 로그를 분석하여 퇴사 위험군을 예측하는 모델은 직원의 사생활 침해 및 프로파일링에 의한 불이익을 야기할 수 있어 매우 엄격한 규제가 적용됩니다. 유럽 인공지능법(EU AI Act) 부속서 3에 따르면 이는 근로자 관리 목적의 고위험 AI 시스템으로 분류됩니다. 기업은 제10조에 따라 데이터 처리 과정의 투명성을 완벽히 보장해야 하며, 의무 불이행 시 제71조에 따라 거액의 과징금이 부과될 수 있습니다.\n한국 인공지능기본법 제2조를 근거로 볼 때에도 해당 시스템은 직원의 고용 관계 및 생계에 중대한 영향을 미치는 '고영향 인공지능'으로 분류될 가능성이 높습니다. 따라서 기업은 제34조에 따라 사전에 위험 관리 계획을 수립하고 신뢰성을 확보하기 위한 조치를 취해야 할 의무가 발생합니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 해당 AI 시스템을 주로 어느 국가(시장)에서 서비스하실 계획인가요?\n* 분석하는 메신저 접속 로그에 업무 외적인 사적 대화 내용이나 노조 활동 관련 정보가 포함되어 있나요?\n* 데이터 수집 및 분석 과정에 대해 직원들에게 사전 고지하고 명시적인 동의를 받는 절차가 마련되어 있나요?\n\n- 규제 대상: 고용 및 근로자 관리 목적으로 직원의 행동을 평가하는 고위험 AI 및 고영향 인공지능\n- 핵심 의무: 데이터 처리 과정의 투명성 보장(EU), 위험 관리 체계 구축(한국)\n- 위반 리스크: 고위험 의무 위반 제재 및 직원 권리 침해 분쟁\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제10조, 제71조 및 부속서 3, 한국 인공지능기본법 제2조, 제34조"
  },
  {
    "question": "우리 회사의 광고 AI 툴이 다른 회사의 로고를 비슷하게 베껴서 결과물을 냈고, 그걸 담당 직원이 그대로 광고에 써서 내용증명을 받았습니다. 책임은 AI 솔루션을 만든 제공자에게 있는 거 아닙니까?",
    "answer": "직원이 자사 광고 업무에 AI 솔루션을 이용한 결과물을 그대로 외부에 공표한 이상, 일차적인 책임은 배포자인 귀사에 부여될 가능성이 높습니다. 유럽 인공지능법(EU AI Act) 제50조에 따르면, AI 생성물을 활용하여 대외적으로 소통할 때 해당 사실을 명확히 고지할 투명성 의무가 사용자(배포자)에게 있습니다.\n한국 인공지능기본법의 경우 해당 상황에 대한 면책 조항이 구체적으로 세분화되어 있지는 않으나, 인공지능 신뢰성 확보 및 투명성 고지 의무 관련 조항을 포괄적으로 확장하여 해석할 때 AI 생성 콘텐츠임을 명시하지 않은 기업의 책임이 인정될 수 있습니다. 다만, 귀사가 AI 툴 벤더사와 맺은 계약 내에 지식재산권 면책(Indemnification) 조항이 있다면 제공자에게 구상권을 청구할 수 있습니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 해당 AI 시스템(광고 송출)을 주로 어느 국가(시장)에서 서비스하셨나요?\n* 광고 AI 툴을 도입할 때 벤더사와 체결한 라이선스 및 지식재산권 면책 조항이 있나요?\n* 외부에 광고를 배포하기 전, 담당 직원이 결과물에 대해 사전 검수를 진행하는 내부 프로세스가 있었나요?\n\n- 규제 대상: AI 시스템을 활용하여 이미지, 영상 등 콘텐츠를 배포하는 기업\n- 핵심 의무: AI 생성 콘텐츠임을 명확히 고지하는 투명성 의무 준수\n- 위반 리스크: 저작권 침해 분쟁 및 투명성 의무 위반에 따른 법적 책임 발생\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조, 한국 인공지능기본법 관련 원칙 조항"
  },
  {
    "question": "한국 본사에서 학습시킨 이력서 평가 AI 모델을 유럽 지사 채용 시스템에 그대로 이식해서 사용하려고 합니다. 한국인 데이터로만 학습되었는데 유럽에서 그대로 써도 규제 위반이 아닐까요?",
    "answer": "한국 본사에서 한국인 데이터로만 학습시킨 AI 모델을 유럽 지사 채용 시스템에 그대로 도입하는 것은 심각한 법적 리스크를 초래합니다. 유럽 인공지능법(EU AI Act) 제10조는 고위험 AI 시스템의 학습 데이터셋이 시스템이 사용될 대상 인구의 지리적, 행동적 특성을 적절히 반영해야 한다고 엄격히 명시하고 있습니다. 채용 모델은 부속서 3에 따라 고위험 AI로 분류되므로, 유럽 현지 지원자의 데이터가 배제된 채로 배포될 경우 알고리즘 편향에 따른 차별 소송은 물론, 제71조에 따라 거액의 과징금이 부과될 수 있습니다. 따라서 유럽 시장 출시에 앞서 현지 인구 특성을 반영하여 모델을 재학습하는 절차가 필수적입니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 모델 파인튜닝 과정에서 유럽 현지 지원자의 데이터를 합법적으로 수집하여 재학습할 계획이 마련되어 있나요?\n* 시스템 운영 중 편향성을 모니터링하고 시정할 수 있는 데이터 품질 관리 프로세스가 내부에 구축되어 있습니까?\n\n- 규제 대상: 채용 및 인사 평가를 위해 사용되는 고위험 AI 시스템\n- 핵심 의무: 사용 대상 인구의 특성을 반영한 대표성 있는 데이터셋 구축\n- 위반 리스크: 알고리즘 편향에 따른 차별 소송 및 과징금 부과\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제10조, 제71조 및 부속서 3"
  },
  {
    "question": "직원들 연차 조회나 사내 식당 메뉴 알려주는 사내망 챗봇 만들 건데, 이것도 AI 법안 신경 써야 하나요?",
    "answer": "단순 정보 제공 목적의 사내망 챗봇은 사람의 생계나 권리에 직접적인 영향을 미치지 않으므로 고위험 AI로 분류되지는 않으나, 투명성 의무는 반드시 준수해야 합니다. 유럽 인공지능법(EU AI Act) 제50조에 따르면, 인간과 상호작용하는 AI 시스템을 제공하는 자는 사용자가 AI와 대화하고 있음을 명확히 인지할 수 있도록 고지할 의무가 있습니다.\n한국 인공지능기본법 역시 현재 챗봇에 대한 세부적인 처벌 규정이 명시되어 있지는 않으나, 정보 제공의 신뢰성 확보라는 기본 조항을 포괄적으로 해석할 때 챗봇이 실제 사람인 것처럼 직원을 기만하는 행위는 리스크를 유발할 수 있습니다. 따라서 대화창에 \"본 챗봇은 AI입니다\"라는 문구를 삽입하는 최소한의 조치가 필요합니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 해당 챗봇을 주로 어느 국가(지사)의 직원들에게 서비스하실 계획인가요?\n* 챗봇 진입 화면에 사용자가 AI와 대화 중임을 알 수 있는 고지 배너가 설정되어 있나요?\n* 챗봇이 직원의 민감한 인사 정보(병가 사유 등)를 수집하여 분석하는 기능이 추후 포함될 수 있습니까?\n\n- 규제 대상: 인간과 직접 상호작용하는 사내 AI 챗봇\n- 핵심 의무: 사용자가 AI와 상호작용하고 있음을 명확히 알리는 투명성 고지\n- 위반 리스크: 투명성 고지 의무 미준수에 따른 제재\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조, 한국 인공지능기본법 관련 원칙 조항"
  },
  {
    "question": "유럽에서 서비스 중인 프리랜서 중개 플랫폼에 AI 알고리즘을 도입해서, 의뢰인에게 가장 적합한 프리랜서를 자동 매칭하고 보수를 제안하는 기능을 넣으려 합니다. 법적 제재가 있을까요?",
    "answer": "유럽에서 서비스 중인 프리랜서 중개 플랫폼에 업무를 자동 할당하고 보수를 결정하는 AI를 도입하는 것은, 유럽 인공지능법(EU AI Act) 부속서 3에 명시된 '근로자 관리 및 작업 할당' 목적의 고위험 AI 시스템에 해당합니다. 이러한 시스템은 프리랜서의 생계와 노동권에 직접적인 영향을 미치기 때문에, AI가 단독으로 결정을 내리는 완전 자동화는 법적으로 매우 위험합니다. 따라서 제14조에 따른 '인적 감독(Human Oversight)' 의무를 철저히 준수하여 프리랜서가 결과에 이의를 제기할 수 있는 채널을 마련해야 하며, 위반 시 제71조에 따라 과징금 처분을 받을 수 있습니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 보수 산정이나 업무 배정에 대해 AI가 아닌 인간 관리자에게 재검토를 요청할 수 있는 기능이 플랫폼 내에 구현되어 있나요?\n* 알고리즘이 성별, 국적 등의 민감한 데이터를 배제하고 공정하게 평가하도록 설계되었는지 내부 검증을 마쳤습니까?\n\n- 규제 대상: 작업 할당 및 보수 결정 목적으로 사용되는 고위험 AI 시스템\n- 핵심 의무: 매칭 결과에 인간이 개입하여 이의를 처리할 수 있는 인적 감독 체계 마련\n- 위반 리스크: 의무 불이행에 따른 강력한 행정 제재 및 과징금 부과\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제14조, 제71조 및 부속서 3"
  },
  {
    "question": "신입사원들 노무 관련 질문에 대답해 주는 AI 에이전트를 도입하려고 합니다. 위험한가요?",
    "answer": "노무 관련 질문에 대답해 주는 AI 에이전트는 사용자와 상호작용하므로 유럽 인공지능법(EU AI Act) 제50조에 따른 투명성 의무(AI임을 고지할 의무) 대상이 됩니다. 나아가 노무라는 민감한 영역을 다루기 때문에 AI가 잘못된 법적 해석을 내놓을 경우 직원의 권리 침해로 이어질 수 있습니다.\n현재 한국 인공지능기본법에는 사내 노무 챗봇에 특화된 세부 제재 조항이 명시되어 있지는 않습니다. 그러나 법안의 신뢰성 확보 및 권리 보호 조항을 넓게 해석할 때, AI의 오답이 사내 취업규칙이나 근로기준법과 충돌하여 노사 분쟁을 유발할 경우 전적인 책임이 기업에 전가될 규제 리스크가 존재합니다. 따라서 주기적으로 사내 노무사가 AI 답변을 검수하는 인적 통제 프로세스가 강력히 권고됩니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 해당 AI 시스템을 주로 어느 국가(지사)에서 서비스하실 계획인가요?\n* 챗봇 대화창 하단에 \"최종적인 법적 효력은 사내 취업규칙을 따릅니다\"와 같은 면책/고지 문구를 삽입하셨나요?\n* AI가 답변을 생성할 때 사내 최신 취업규칙만을 참조하도록 검색 범위가 제한되어 있습니까?\n\n- 규제 대상: 직원과 상호작용하며 사내 규정을 안내하는 AI 챗봇\n- 핵심 의무: AI 시스템임을 알리는 투명성 의무 및 신뢰성 확보\n- 위반 리스크: 잘못된 정보 제공으로 인한 사내 노사 분쟁 및 투명성 위반\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조, 한국 인공지능기본법 관련 원칙 조항"
  },
  {
    "question": "급여 명세서와 퇴직금 정산을 AI가 자동으로 계산하고 지급 승인까지 하도록 시스템을 자동화하려 합니다. 유럽 지사에도 적용할 건데 법적 검토 부탁드립니다.",
    "answer": "급여와 퇴직금을 AI가 계산하고 인간의 개입 없이 최종 승인까지 내리는 시스템을 유럽 지사에 도입하는 것은 직원의 재산권에 중대한 영향을 미치므로, 유럽 인공지능법(EU AI Act) 부속서 3에 따른 고용 영역의 '고위험 AI 시스템'으로 엄격히 분류됩니다. 기업은 제14조에서 규정하는 '인적 감독(Human Oversight)' 의무를 반드시 준수해야 합니다. 즉, AI가 단독으로 처리하는 완전 자동화 방식은 법적으로 금지되며, 산정된 금액을 지급하기 전 인간 담당자가 결과를 검증하거나 직원이 이의를 제기할 수 있는 개입 장치를 필수로 마련해야 합니다. 이를 이행하지 않을 경우 노동법 위반 및 강력한 제재를 받을 수 있습니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 급여 및 퇴직금 내역이 최종 지급되기 전, 재무 담당자가 이를 승인하는 검증 절차가 시스템에 구현되어 있나요?\n* 직원들이 정산 결과에 이의가 있을 경우, 즉시 인간 관리자에게 재검토를 요청할 수 있는 채널이 제공됩니까?\n\n- 규제 대상: 급여 및 퇴직금 정산에 관여하는 고위험 AI 시스템\n- 핵심 의무: 자동화된 의사결정에 개입할 수 있는 인적 감독 의무\n- 위반 리스크: 고위험 AI 의무 미이행에 따른 행정 제재 및 소송\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제14조 및 부속서 3"
  }
]