[
  {
    "question": "이번에 인사팀에서 이력서 검토 시간을 줄이려고 AI 자동 필터링 솔루션을 도입하려고 하는데요. 이거 법적으로 문제 되는 부분 있을까요?",
    "answer": "인사팀에서 이력서 검토를 위해 도입하려는 AI 자동 필터링 솔루션은 유럽 인공지능법(EU AI Act) 부속서 3에 따라 채용에 직접적으로 관여하는 고위험 AI로 분류될 가능성이 높습니다. 또한, 한국의 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법 제2조 및 제24조에 따라 이용자의 권리에 중대한 영향을 미치는 고영향 인공지능에 해당할 수 있습니다. 따라서 해당 AI 솔루션이 서류 탈락 여부를 단독으로 결정하는지, 아니면 단순 보조 도구로 활용되는지에 따라 기업이 준수해야 할 신뢰성 확보 의무와 규제 강도가 크게 달라집니다. 위반 시 구체적인 벌칙은 도입 방식에 따라 다르나, 규제를 준수하지 않을 경우 법적 제재가 발생할 수 있습니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 이 AI 시스템이 채용 탈락 결정에 직접적이고 최종적인 권한을 가지나요?\n* AI가 분석하는 이력서 데이터에 지원자의 민감 정보(종교, 출신 지역 등)가 포함되어 있나요?\n\n- 규제 대상: 채용 및 인사 관리에 사용되는 고위험 AI 및 고영향 인공지능\n- 핵심 의무: AI 개입 수준에 따른 신뢰성 확보 및 위험 관리 의무\n- 위반 리스크: 고위험 AI 규제 위반에 따른 법적 제재 가능성\n- 근거 조항: 한국 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법 제2조 및 제24조, 유럽 인공지능법(EU AI Act) 부속서 3"
  },
  {
    "question": "한국 인공지능기본법에서 말하는 '고영향 AI' 기준이랑, 유럽 AI Act의 고위험 AI 기준이 어떻게 연결돼? 한국에서 서비스할 때 유럽 법안의 어떤 부분을 보완해서 참고해야 할까?",
    "answer": "한국 인공지능기본법의 '고영향 AI'와 유럽 AI Act의 '고위험 AI'는 모두 AI 시스템이 인간의 권리와 생계에 미치는 중대한 영향을 기준으로 규제 대상을 설정한다는 점에서 깊이 연결되어 있습니다. 한국의 기본법에서는 AI가 이용자의 권리에 중대한 영향을 미치는지 사전에 검토하고 필요시 확인을 요청하도록 규정하고 있습니다. 반면, 유럽 AI Act는 특정 분야(채용, 의료 등)나 안전 구성 요소로 사용되는 시스템을 명시적으로 고위험 AI로 분류하여 엄격한 제3자 적합성 평가를 요구합니다. 따라서 한국에서 AI 서비스를 제공하더라도 글로벌 확장을 고려한다면, 유럽 AI Act의 세밀한 고위험 분류 기준과 강력한 사전 적합성 평가 절차를 보완적으로 참고하여 선제적인 위험 관리 체계를 구축해야 합니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 현재 기획 중인 AI 서비스가 주로 어떤 산업 분야(예: 금융, 의료, 인사 등)에서 활용될 예정인가요?\n* 추후 유럽 시장으로 서비스를 확장하거나 유럽 거주자의 데이터를 처리할 계획이 있나요?\n\n- 규제 대상: 한국 인공지능기본법의 고영향 인공지능 및 유럽 AI Act의 고위험 AI 시스템\n- 핵심 의무: 고영향 AI 사전 검토(한국) 및 고위험 AI 제3자 적합성 평가(유럽)\n- 위반 리스크: 각 법안에 명시된 규제 미준수에 따른 행정적 제재 및 시장 출시 제한\n- 근거 조항: 한국 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법, 유럽 인공지능법(EU AI Act)"
  },
  {
    "question": "유럽 지사 채용 과정에서 지원자의 표정과 목소리 톤을 분석해서 스트레스 저항성을 평가하는 AI 면접 툴을 전면 도입하려고 합니다. 위반 시 페널티와 미리 준비해야 할 사항이 궁금합니다.",
    "answer": "유럽 지사 채용 과정에서 지원자의 표정과 목소리 톤을 분석해 감정을 추론하는 AI 면접 툴의 도입은 유럽 인공지능법(EU AI Act) 제5조에 따라 원칙적으로 전면 금지되는 행위입니다. 직장 내에서 생체 인식 및 감정 인식을 사용하는 것은 지원자의 기본권을 심각하게 침해하는 것으로 간주되기 때문입니다. 만약 이를 강행하여 금지 조항을 위반할 경우, 제71조에 따라 최대 3,500만 유로 또는 전 세계 매출의 7% 중 더 높은 금액이 과징금으로 부과되는 치명적인 리스크가 발생합니다. 따라서 해당 프로젝트는 전면 재검토가 필요하며, 단순 역량 평가 AI로 선회하더라도 부속서 3에 따른 고위험 AI에 해당하여 제14조의 인적 감독 의무를 필수적으로 준수해야 합니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 해당 AI 툴의 도입 목적을 감정 추론이 아닌 단순 직무 역량(언어 구사력 등) 평가로 변경할 여지가 있나요?\n* 시스템에서 수집하는 음성 및 영상 데이터의 보관 주기나 파기 방식은 어떻게 설계되어 있나요?\n\n- 규제 대상: 직장 내 감정을 추론하는 생체 인식 및 감정 인식 AI (원칙적 금지 대상)\n- 핵심 의무: 금지된 AI 관행 중단 및 고위험 AI 전환 시 인적 감독 의무 준수\n- 위반 리스크: 최대 3,500만 유로 또는 전 세계 매출의 7% 과징금 부과\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제5조(금지된 관행), 제14조(인적 감독), 제71조(벌칙) 및 부속서 3"
  },
  {
    "question": "내부 인트라넷 활동 로그와 메신저 접속 시간을 데이터로 활용해서 퇴사 고위험군 직원을 예측하는 AI 모델을 자체 개발 중입니다. 데이터 수집과 활용 면에서 준수해야 할 법적 가이드라인이 있나요?",
    "answer": "내부 인트라넷 활동과 메신저 접속 로그를 활용하여 직원의 행동을 모니터링하고 퇴사 위험군을 예측하는 모델은, 유럽 인공지능법(EU AI Act) 부속서 3에 따라 근로자 관리 목적의 고위험 AI 시스템으로 분류됩니다. 이러한 모델은 직원의 사생활을 침해하고 프로파일링에 의한 차별적 처우를 야기할 수 있으므로 매우 엄격한 규제가 적용됩니다. 기업은 제10조에 따라 데이터 처리 과정의 투명성을 완벽히 보장해야 하며, 제12조에 명시된 시스템 로그 기록 유지 의무를 준수해야 합니다. 이러한 고위험 AI 의무를 불이행할 경우 제71조에 따라 최대 1,500만 유로 또는 전 세계 매출의 3%에 달하는 거액의 과징금이 부과될 수 있습니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 분석하는 메신저 접속 로그에 업무 외적인 사적 대화 내용이나 노조 활동 관련 정보가 포함되어 있나요?\n* 데이터 수집 및 분석 과정에 대해 직원들에게 사전 고지하고 명시적인 동의를 받는 절차가 마련되어 있나요?\n\n- 규제 대상: 고용 및 근로자 관리 목적으로 직원의 행동을 평가하는 고위험 AI\n- 핵심 의무: 데이터 처리 과정의 투명성 보장 및 시스템 로그 기록 유지\n- 위반 리스크: 최대 1,500만 유로 또는 전 세계 매출의 3% 과징금 부과\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제10조(데이터 거버넌스), 제12조(기록 유지), 제71조(벌칙), 부속서 3"
  },
  {
    "question": "우리 회사의 광고 AI 툴이 다른 회사의 로고를 비슷하게 베껴서 결과물을 냈고, 그걸 담당 직원이 그대로 광고에 써서 내용증명을 받았습니다. 책임은 AI 솔루션을 만든 제공자에게 있는 거 아닙니까?",
    "answer": "직원이 자사 광고 업무에 AI 솔루션을 이용한 결과물을 그대로 외부에 공표한 이상, 생성된 이미지가 AI를 기반으로 제작되었음을 명시하지 않은 투명성 위반 책임과 저작권 침해 방조 책임은 일차적으로 배포자인 귀사에 부여됩니다. 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act) 제50조에 따르면, AI 생성물을 활용하여 대외적으로 소통할 때 해당 사실을 명확히 고지할 의무가 있습니다. 다만, 귀사가 AI 솔루션 제공자(벤더사)와 맺은 이용 계약 내에 산출물로 인한 저작권 분쟁 발생 시의 책임 배상 조항이 포함되어 있다면, 이를 근거로 제공자에게 구상권을 청구할 수 있습니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 해당 광고 AI 툴을 도입할 때 벤더사와 체결한 라이선스 및 지식재산권 면책 조항(Indemnification)이 있나요?\n* 외부에 광고를 배포하기 전, 담당 직원이 결과물에 대해 사전 검수를 진행하는 내부 프로세스가 있었나요?\n\n- 규제 대상: AI 시스템을 활용하여 이미지, 영상 등 콘텐츠를 생성하고 배포하는 기업(사용자)\n- 핵심 의무: AI 생성 콘텐츠임을 명확히 고지하는 투명성 의무 준수\n- 위반 리스크: 저작권 침해 분쟁 및 투명성 의무 위반에 따른 법적 책임 발생\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)"
  },
  {
    "question": "한국 본사에서 학습시킨 이력서 평가 AI 모델을 유럽 지사 채용 시스템에 그대로 이식해서 사용하려고 합니다. 한국인 데이터로만 학습되었는데 유럽에서 그대로 써도 규제 위반이 아닐까요?",
    "answer": "한국 본사에서 한국인 데이터로만 학습시킨 이력서 평가 AI 모델을 유럽 지사 채용 시스템에 그대로 도입하는 것은, 유럽 인공지능법(EU AI Act)의 데이터 거버넌스 규정을 위반하는 행위이며 심각한 법적 리스크를 초래합니다. 한국 인공지능기본법과 유럽 AI Act는 모두 AI의 편향성 방지와 신뢰성 확보를 강조하지만, 특히 유럽 인공지능법(EU AI Act) 제10조는 고위험 AI 시스템의 학습 데이터셋이 시스템이 사용될 대상 인구의 지리적, 행동적 특성을 적절히 반영해야 한다고 명시하고 있습니다. 채용에 관여하는 이 모델은 부속서 3에 따라 고위험 AI로 분류되므로, 유럽 현지 지원자의 데이터가 배제된 채로 배포될 경우 알고리즘 편향에 따른 차별 소송은 물론, 제71조에 따라 거액의 과징금이 부과될 수 있습니다. 따라서 유럽 시장에 출시하기 전 현지 인구 특성을 반영하여 모델을 재학습하고 검증하는 보완 절차가 필수적입니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 모델 파인튜닝 과정에서 유럽 현지 지원자의 데이터를 합법적으로 수집하여 재학습할 계획이 마련되어 있나요?\n* 편향성을 모니터링하고 시정할 수 있는 데이터 품질 관리 프로세스가 내부에 구축되어 있습니까?\n\n- 규제 대상: 채용 및 인사 평가를 위해 사용되는 고위험 AI 시스템\n- 핵심 의무: 사용 대상 인구의 특성을 반영한 대표성 있는 데이터셋 구축 및 편향성 관리\n- 위반 리스크: 알고리즘 편향에 따른 차별 소송 및 과징금 부과\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제10조(데이터의 적절성과 대표성), 제71조(벌칙) 및 부속서 3"
  },
  {
    "question": "직원들 연차 조회나 사내 식당 메뉴 알려주는 사내망 챗봇 만들 건데, 이것도 AI 법안 신경 써야 하나요?",
    "answer": "단순 정보 제공 목적의 사내망 챗봇(연차 조회, 식당 메뉴 안내 등)은 고위험 AI로 분류되지 않으나, 사용자와 직접 상호작용하는 AI 시스템으로서 투명성 의무를 반드시 준수해야 합니다. 유럽 인공지능법(EU AI Act) 제50조에 따르면, 인간과 상호작용하는 AI 시스템을 제공하거나 배포하는 자는 해당 시스템이 AI라는 사실을 사용자가 명확히 인지할 수 있도록 고지해야 할 법적 의무가 있습니다. 만약 챗봇이 사람처럼 응대하여 직원이 이를 실제 인사 담당자로 오인하게 방치할 경우, 투명성 의무 위반으로 제재를 받을 수 있습니다. 비록 엄격한 위험 관리 및 적합성 평가 대상은 아니더라도, 최초 접속 화면이나 대화창 하단에 \"본 챗봇은 AI 시스템입니다\"라는 명시적인 안내 문구를 삽입하는 최소한의 조치가 필요합니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 사내망 챗봇이 구동되는 화면 진입 시, 사용자가 AI와 대화 중임을 명확히 알 수 있는 고지 팝업이나 배너가 설정되어 있나요?\n* 해당 챗봇이 직원의 민감한 인사 정보(예: 병가 사유 등)를 수집하여 별도로 저장하거나 분석하는 기능이 포함되어 있습니까?\n\n- 규제 대상: 인간(직원)과 직접 상호작용하는 범용 AI 챗봇 시스템\n- 핵심 의무: 사용자가 AI 시스템과 상호작용하고 있음을 명확히 알리는 투명성 고지 의무\n- 위반 리스크: 투명성 고지 의무 미준수에 따른 제재\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(특정 AI 시스템의 투명성 의무)"
  },
  {
    "question": "유럽에서 서비스 중인 프리랜서 중개 플랫폼에 AI 알고리즘을 도입해서, 의뢰인에게 가장 적합한 프리랜서를 자동 매칭하고 보수를 제안하는 기능을 넣으려 합니다. 법적 제재가 있을까요?",
    "answer": "유럽에서 서비스 중인 프리랜서 중개 플랫폼에 업무를 자동 할당하고 보수를 결정하는 AI 알고리즘을 도입하는 것은, 유럽 인공지능법(EU AI Act) 부속서 3에 명시된 '근로자 관리 및 작업 할당' 목적의 고위험 AI 시스템에 해당하여 매우 엄격한 규제를 받게 됩니다. 이러한 시스템은 프리랜서의 생계와 노동권에 직접적인 영향을 미치기 때문에, 알고리즘에 의한 차별이나 불공정한 보수 산정이 발생하지 않도록 제14조에 따른 '인적 감독(Human Oversight)' 의무를 반드시 준수해야 합니다. AI가 단독으로 업무 배정이나 보수 삭감을 확정 짓는 완전 자동화 방식은 법적으로 위험하며, 프리랜서가 결과에 대해 이의를 제기하고 사람(플랫폼 관리자)이 이를 재검토 및 수정할 수 있는 시스템적 채널을 마련해야 합니다. 만약 이를 이행하지 않을 경우, 제71조에 따라 최대 1,500만 유로에 달하는 과징금 처분을 받을 수 있습니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 프리랜서가 배정된 업무나 산정된 보수에 대해 AI가 아닌 인간 관리자에게 재검토를 요청할 수 있는 이의 제기 기능이 플랫폼 내에 구현되어 있나요?\n* 보수 산정 알고리즘이 성별, 국적 등의 민감한 데이터를 배제하고 공정하게 평가하도록 설계되었는지 내부 검증을 마쳤습니까?\n\n- 규제 대상: 근로자 관리, 작업 할당 및 보수 결정 목적으로 사용되는 고위험 AI 시스템\n- 핵심 의무: 매칭 및 보수 산정 결과에 인간이 개입하여 이의를 처리할 수 있는 인적 감독 체계 마련\n- 위반 리스크: 고위험 AI 의무 불이행에 따른 최대 1,500만 유로의 과징금 부과\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제14조(인적 감독), 제71조(벌칙) 및 부속서 3"
  },
  {
    "question": "신입사원들 노무 관련 질문에 대답해 주는 AI 에이전트를 도입하려고 합니다. 위험한가요?",
    "answer": "신입사원의 노무 관련 질문에 대답해 주는 AI 에이전트는 제공하는 정보의 성격상 노사 분쟁을 유발할 수 있는 잠재적 리스크가 있으나, 원칙적으로는 '상호작용 AI'로서 투명성 의무의 적용 대상이 됩니다. 유럽 인공지능법(EU AI Act) 제50조에 따르면, 기업은 직원이 인간이 아닌 AI 시스템과 대화하고 있다는 사실을 명확히 인지할 수 있도록 고지할 법적 의무가 있습니다. 나아가 노무라는 민감한 영역을 다루기 때문에 AI가 제공한 잘못된 답변이 근로계약이나 취업규칙과 충돌할 경우, 기업이 그 책임을 전적으로 부담하게 될 위험이 큽니다. 따라서 고위험 AI 수준의 엄격한 적합성 평가가 필수적인 것은 아니지만, AI의 답변 내용을 주기적으로 사내 노무사나 법무팀이 모니터링하여 법적 정합성을 검수하는 내부 통제 프로세스를 마련하는 것이 강력히 권고됩니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* 챗봇 대화창 하단이나 진입 화면에 \"본 답변은 AI에 의해 생성되었으며, 최종적인 법적 효력은 사내 취업규칙을 따릅니다\"와 같은 고지 문구를 삽입하셨나요?\n* AI가 답변을 생성할 때, 사내 최신 취업규칙이나 근로기준법 데이터베이스만을 참조하도록 검색 범위가 제한되어 있습니까?\n\n- 규제 대상: 직원과 상호작용하여 정보를 제공하는 사내 AI 챗봇\n- 핵심 의무: 대화 상대가 AI 시스템임을 명시적으로 알리는 투명성 의무\n- 위반 리스크: 투명성 고지 위반 제재 및 잘못된 정보 제공으로 인한 사내 노사 분쟁\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)"
  },
  {
    "question": "급여 명세서와 퇴직금 정산을 AI가 자동으로 계산하고 지급 승인까지 하도록 시스템을 자동화하려 합니다. 유럽 지사에도 적용할 건데 법적 검토 부탁드립니다.",
    "answer": "급여 명세서와 퇴직금을 AI가 자동으로 계산하고 인간의 개입 없이 최종 지급 승인까지 내리는 시스템을 유럽 지사에 도입하는 것은, 직원의 재산권과 생계에 중대한 영향을 미치므로 유럽 인공지능법(EU AI Act) 부속서 3에 따른 고용 영역의 '고위험 AI 시스템'으로 엄격히 분류됩니다. 특히 기업은 고위험 AI 시스템에 대해 제14조에서 규정하는 '인적 감독(Human Oversight)' 의무를 철저히 준수해야 합니다. 즉, AI가 단독으로 최종 승인 결정을 내리는 완전 자동화는 법적으로 매우 위험하며, 산정된 금액을 지급하기 전 담당자가 결과를 검증하거나 직원이 오류를 발견했을 때 즉각적으로 사람에게 이의를 제기할 수 있는 개입 장치가 반드시 마련되어야 합니다. 이러한 의무를 이행하지 않고 유럽 지사에 배포할 경우, 노동법 위반은 물론 강력한 법적 제재를 받게 됩니다.\n\n더욱 정확한 맞춤형 규제 리스크를 진단하기 위해, 추가로 확인이 필요한 사항은 다음과 같습니다.\n* AI가 계산한 급여 및 퇴직금 정산 내역이 최종 지급되기 전, 재무 담당자가 이를 승인하는 검증 절차가 시스템에 구현되어 있나요?\n* 직원들이 급여 정산 결과에 이의가 있을 경우, 즉시 인간 관리자에게 재검토를 요청할 수 있는 기능이 제공됩니까?\n\n- 규제 대상: 직원의 급여 및 퇴직금 계산, 처우 결정에 관여하는 고위험 AI 시스템\n- 핵심 의무: 자동화된 의사결정에 대한 인간의 검증 및 오류 발생 시 개입할 수 있는 인적 감독 의무\n- 위반 리스크: 고위험 AI 의무 미이행에 따른 강력한 행정 제재 및 노동법 위반 소송\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제14조(인적 감독) 및 부속서 3"
  }
]