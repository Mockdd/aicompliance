[
  {
    "question": "이번에 인사팀에서 이력서 검토 시간을 줄이려고 AI 자동 필터링 솔루션을 도입하려고 하는데요. 이거 법적으로 문제 되는 부분 있을까요?",
    "answer": "도입하시려는 AI 솔루션이 서류 탈락 여부를 단독으로 결정하는지, 혹은 인사 담당자의 단순 키워드 매칭 보조 도구로서 활용되는 것인지에 따라 고위험 AI 분류 여부와 신뢰성 확보 의무가 크게 달라집니다. 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법 제2조 및 제24조에 따라 이용자의 권리에 중대한 영향을 미치는 경우 고영향 인공지능으로 분류되며, 유럽 인공지능법(EU AI Act) 부속서 3에 따르면 채용에 관여하는 AI는 고위험 AI로 분류되어 엄격한 규제를 받으므로 AI의 개입 수준에 대한 추가 확인이 필요합니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 모두 포함하여 답변드립니다.\n- 근거 조항: 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법 제2조(정의) 및 제24조(신뢰성 확보), 유럽 인공지능법(EU AI Act) 부속서 3(고위험 AI 시스템)."
  },
  {
    "question": "유럽 지사 채용 과정에서 지원자의 표정과 목소리 톤을 분석해서 스트레스 저항성을 평가하는 AI 면접 툴을 전면 도입하려고 합니다. 위반 시 페널티와 미리 준비해야 할 사항이 궁금합니다.",
    "answer": "해당 솔루션은 직장 내에서 지원자의 감정을 추론하는 생체 인식 기술을 사용하는 행위로, 원칙적으로 사용이 전면 금지되며 이를 강행할 경우 막대한 매출 비례 과징금 처분을 받게 되는 치명적인 규제 위반 사항입니다. 또한 단순 역량 평가 AI로 선회하더라도 수집되는 음성 및 영상 데이터의 보관 주기나 파기 방식에 따라 별도의 의무가 추가될 수 있으므로 데이터 처리 방침에 대한 세부 확인이 필요합니다. 유럽 지사에서의 도입이므로 유럽 인공지능법(EU AI Act)을 위주로 답변드리며, 관련성이 높은 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법의 방향성을 함께 참고로 제시합니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 제5조에 따라 직장 내에서 감정을 추론하는 생체 인식 및 감정 인식 AI는 원칙적으로 사용이 금지됩니다.\n- 핵심 의무: 예외적 허용 범위가 아니므로 프로젝트 전면 재검토가 필요합니다. 단순 역량 평가 AI로 전환하더라도 부속서 3에 따라 고위험 AI에 해당하여 제14조에 명시된 인적 감독이 필수적으로 요구됩니다.\n- 위반 리스크: 제71조에 따라 감정 인식 AI 금지 조항 위반 시 최대 3,500만 유로 또는 전 세계 매출의 7% 중 높은 금액이 과징금으로 부과됩니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제5조(금지된 인공지능 관행), 제14조(인적 감독), 제71조(벌칙), 부속서 3."
  },
  {
    "question": "직원들 인사 고과 매길 때 객관성을 높이려고 AI 평가 시스템을 써볼까 하는데 괜찮을까요?",
    "answer": "직원 평가를 위한 AI 도입은 승진이나 연봉 협상 등 직원의 처우에 AI가 직접적인 영향을 미치는지, 혹은 관리자의 단순 참고용 리포트로만 활용되는지에 따라 고위험 AI 해당 여부와 인적 감독 의무 수준이 결정되는 민감한 영역입니다. 처우에 직접적 영향을 미칠 경우 유럽 인공지능법(EU AI Act) 부속서 3에 따라 엄격한 기준을 적용받으므로 활용 범위 점검이 필요합니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법 제2조(정의), 유럽 인공지능법(EU AI Act) 부속서 3(고위험 AI 시스템)."
  },
  {
    "question": "내부 인트라넷 활동 로그와 메신저 접속 시간을 데이터로 활용해서 퇴사 고위험군 직원을 예측하는 AI 모델을 자체 개발 중입니다. 데이터 수집과 활용 면에서 준수해야 할 법적 가이드라인이 있나요?",
    "answer": "해당 모델은 직원의 사생활 침해 및 프로파일링에 의한 차별적 처우 등 법적 분쟁을 야기할 수 있으며, 고위험 AI 요건 미준수 시 거액의 과징금이 부과될 수 있으므로 근로자 동의와 투명성 확보 조치가 선행되어야 합니다. 모델이 분석하는 메신저 접속 로그에 업무 외적인 사적 대화 기록이나 노조 활동 관련 정보가 포함되는지 추가 확인이 필요합니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 부속서 3에 따라 고용 및 근로자 관리 목적의 고위험 AI에 해당합니다.\n- 핵심 의무: 유럽 인공지능법(EU AI Act) 제10조에 따른 데이터 처리 과정의 투명성 보장 및 제12조에 따른 시스템 로그 기록 유지가 법적 의무입니다.\n- 위반 리스크: 고위험 AI 의무 불이행 시 제71조에 따라 최대 1,500만 유로 또는 전 세계 매출의 3% 과징금이 부과될 수 있습니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제10조(데이터 거버넌스), 제12조(기록 유지), 제71조(벌칙), 부속서 3."
  },
  {
    "question": "사내 직무 교육용으로 AI 챗봇 튜터를 붙여주려고 합니다. 법적으로 걸리는 게 있을까요?",
    "answer": "사내 교육용 AI 튜터는 챗봇이 단순히 직무 지식을 전달하는 것을 넘어, 직원의 교육 이수 결과나 평가 점수를 산정하여 인사팀의 고과에 개입하는지 여부에 따라 고위험 AI 분류가 결정됩니다. 또한 유럽 인공지능법(EU AI Act) 제50조에 따라 사용자가 AI와 대화하고 있다는 사실을 반드시 고지해야 하므로 UI 상의 안내 문구 반영 여부를 확인해 주시기 바랍니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무), 부속서 3(교육 관련 AI), 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법 이용자 보호 조항."
  },
  {
    "question": "한국 본사에서 학습시킨 이력서 평가 AI 모델을 유럽 지사 채용 시스템에 그대로 이식해서 사용하려고 합니다. 한국인 데이터로만 학습되었는데 유럽에서 그대로 써도 규제 위반이 아닐까요?",
    "answer": "학습 데이터가 유럽 현지 인구의 특성을 반영하지 못할 경우 알고리즘 편향에 따른 채용 차별 소송 및 데이터 거버넌스 위반에 따른 벌금이 부과되는 치명적인 문제가 발생합니다. 모델 파인튜닝 과정에서 유럽 현지 지원자의 데이터가 지리적, 행동적 특성을 반영할 수 있도록 충분히 확보 및 재학습되었는지 확인이 필요합니다. 한국 본사에서 개발하여 유럽 지사에 도입하는 사안이므로, 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 모두 고려하여 답변드립니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 부속서 3에 따라 고용 관련 고위험 AI에 해당하며, 배포자로서 유럽 지사 측에 의무가 발생합니다.\n- 핵심 의무: 유럽 인공지능법(EU AI Act) 제10조에 따라, 학습 데이터셋은 시스템이 사용될 대상 인구의 특성을 적절히 반영해야 하므로 재학습이 필수적입니다.\n- 위반 리스크: 제71조에 따라 데이터 거버넌스 위반으로 간주될 경우 최대 3,500만 유로의 벌금이 부과될 수 있습니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제10조(데이터의 적절성과 대표성), 제71조(벌칙), 부속서 3."
  },
  {
    "question": "직원들 연차 조회나 사내 식당 메뉴 알려주는 사내망 챗봇 만들 건데, 이것도 AI 법안 신경 써야 하나요?",
    "answer": "단순 정보 제공용 사내 챗봇은 고위험 규제 대상은 아니지만, 사용자가 AI와 대화하고 있다는 사실을 고지하지 않을 경우 유럽 인공지능법(EU AI Act) 제50조 위반으로 제재를 받을 수 있습니다. 사내망 챗봇의 최초 접속 화면이나 대화창 하단에 고지 문구를 명확히 삽입할 수 있도록 UI 기획이 되어 있는지 확인이 필요합니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(특정 시스템 투명성 의무)."
  },
  {
    "question": "유럽에서 서비스 중인 프리랜서 중개 플랫폼에 AI 알고리즘을 도입해서, 의뢰인에게 가장 적합한 프리랜서를 자동 매칭하고 보수를 제안하는 기능을 넣으려 합니다. 법적 제재가 있을까요?",
    "answer": "AI를 통한 업무 할당과 보수 결정은 노동권 침해 소지가 높아, 투명성을 확보하고 결과에 대한 이의 제기 절차를 마련하지 않을 경우 고위험 AI 의무 미이행으로 엄격한 과징금 처분 대상이 됩니다. 프리랜서가 배정된 업무나 보수에 대해 사람인 관리자에게 재검토를 요청할 수 있는 기능이 플랫폼에 구현되어 있는지 필수적인 점검이 필요합니다. 유럽 현지 서비스이므로 유럽 인공지능법(EU AI Act)을 위주로 답변드립니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 부속서 3에 명시된 근로자 관리 및 작업 할당 목적의 고위험 AI로 분류됩니다.\n- 핵심 의무: 제14조에 따라 매칭 및 보수 산정 결과에 대해 사람이 개입하여 이의 제기를 처리할 수 있는 인적 감독 채널을 반드시 마련해야 합니다.\n- 위반 리스크: 제71조에 따라 고위험 AI 의무 미이행 시 최대 1,500만 유로의 과징금이 발생할 수 있습니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제14조(인적 감독), 제71조(벌칙), 부속서 3."
  },
  {
    "question": "신입사원들 노무 관련 질문에 대답해 주는 AI 에이전트를 도입하려고 합니다. 위험한가요?",
    "answer": "노무 관련 질문 응대 AI는 잘못된 법적 정보 제공으로 인해 노사 분쟁이 발생할 경우 책임 소재가 불분명해지는 리스크가 존재합니다. AI가 제공하는 답변이 근로계약과 충돌하지 않는지 주기적으로 사내 노무사가 모니터링하는 검수 프로세스가 마련되어 있는지, 그리고 대화 상대가 AI임을 안내하는 고지 기능이 있는지 확인해야 합니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "급여 명세서와 퇴직금 정산을 AI가 자동으로 계산하고 지급 승인까지 하도록 시스템을 자동화하려 합니다. 유럽 지사에도 적용할 건데 법적 검토 부탁드립니다.",
    "answer": "급여 등 재산권에 직접 영향을 미치는 시스템에 사람이 개입할 수 있는 검증 단계를 누락할 경우 노동법 위반 및 고위험 AI 의무 불이행으로 강력한 과징금 제재를 받게 됩니다. 급여 정산 오류가 의심될 때 직원이 즉각적으로 담당자에게 재산정을 요구할 수 있는 시스템적 보완 장치가 설계되어 있는지 파악이 필요합니다. 유럽 지사 적용이 포함되어 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 규제 대상: 재산권에 영향을 미치는 분야로서, 유럽 인공지능법(EU AI Act) 부속서 3에 따른 고용 영역 고위험 AI에 해당합니다.\n- 핵심 의무: 자동화된 의사결정만으로 최종 승인을 내리는 것은 지양해야 하며, 유럽 인공지능법(EU AI Act) 제14조에 따라 오류 발생 시 즉각 사람이 개입하여 결과를 수정할 수 있는 시스템적 보완 장치가 의무화되어 있습니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제14조(인적 감독), 부속서 3."
  },
  {
    "question": "이번에 백엔드 개발할 때 외부 오픈소스 LLM 가져와서 API 형태로 우리 서비스에 붙이려고 하는데 라이선스 말고 법적으로 문제 될 게 있을까요?",
    "answer": "오픈소스 LLM이 자사 서비스 내에서 단순히 텍스트 번역 등의 제한적인 기능을 수행하는지, 혹은 고객 상담이나 의료 정보 제공 등 핵심적이고 민감한 영역을 다루는지에 따라 투명성 의무 및 신뢰성 확보 수준이 결정됩니다. 도입하시려는 오픈소스 모델의 이름과 서비스 내 구체적 연동 범위를 알려주시면 상세한 리스크를 확인해 드리겠습니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법 제24조(신뢰성 확보 조치), 유럽 인공지능법(EU AI Act) 제53조(범용 AI 모델 의무)."
  },
  {
    "question": "LLM 성능을 높이려고 유럽 현지 뉴스 사이트랑 커뮤니티 게시글을 무단 크롤링해서 학습 데이터로 썼습니다. 서비스 출시는 한국과 유럽 동시 진행인데 리스크가 어느 정도인가요?",
    "answer": "저작권이 있는 데이터를 무단 크롤링하여 학습하는 행위는 투명성 및 저작권 준수 의무 위반에 해당하여 원저작권자의 민사 소송뿐 아니라 최대 1,500만 유로의 과징금이 부과될 수 있는 매우 중대한 위반 사항입니다. 데이터 크롤링 수집 과정에서 사이트 소유자의 거부(Opt-out) 의사를 기술적으로 우회했는지 추가로 확인이 필요합니다. 한국과 유럽 동시 출시이므로 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 적용하여 답변드립니다.\n- 규제 대상: 범용 AI 제공자로서 유럽 인공지능법(EU AI Act) 제53조의 규제를 받습니다.\n- 핵심 의무: 제53조에 명시된 바에 따라 제공자는 유럽 연합 저작권법을 준수해야 하며, 데이터 소유자가 크롤링을 거부할 수 있는 기술적 장치를 존중하고 학습 데이터의 요약본을 공개해야 합니다.\n- 위반 리스크: 제71조에 따라 최대 1,500만 유로의 과징금이 부과될 수 있습니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제53조(범용 AI 제공자 의무), 제71조(벌칙)."
  },
  {
    "question": "사내 규정집이랑 기안 문서들 벡터 DB에 넣고 RAG 구조로 사내용 챗봇 만드려는데 이건 안전하겠죠?",
    "answer": "폐쇄형 RAG 시스템은 고위험 AI에 해당하지 않으나, 임베딩되는 사내 문서 내에 직원들의 민감한 개인정보가 포함되어 비식별화 처리가 누락될 경우 개인정보보호법에 따른 유출 리스크가 발생합니다. 데이터를 벡터화하기 전 개인정보 마스킹 로직이 구현되어 있는지 점검이 필요하며, 사용자가 AI 챗봇과 소통하고 있음을 고지해야 합니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무) 및 개인정보 관련 법령."
  },
  {
    "question": "매장 보안 강화를 위해 출입구 CCTV 영상으로 고객의 얼굴을 인식하고, 과거 절도 이력 데이터베이스와 실시간으로 대조하는 AI 시스템을 개발 중입니다.",
    "answer": "생체 정보를 이용해 공공장소에서 실시간으로 대조하는 행위는 원칙적으로 전면 금지된 인공지능 관행이며, 적발 시 즉각적인 서비스 폐기 명령과 함께 최고 수준의 과징금이 부과됩니다. 예외적 법 집행 상황이 아니라면 즉시 개발 보류 및 기획 변경을 권고합니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 제5조에 명시된 공공장소에서의 '실시간 원격 생체인식 시스템'에 해당합니다.\n- 핵심 의무: 제5조에 따라 중대 범죄 예방 목적의 법 집행 기관을 제외한 민간 기업의 사용이 전면 금지됩니다. 한국 법안에서도 개인정보보호법상 민감정보 수집에 해당하여 강한 제약이 따릅니다.\n- 위반 리스크: 제71조에 따라 금지된 AI 시스템 사용으로 적발될 경우 최대 3,500만 유로 또는 전 세계 매출의 7%가 부과됩니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제5조(금지된 인공지능 관행), 제71조(벌칙)."
  },
  {
    "question": "테스트용 DB가 부족해서 생성형 AI로 가짜 유저 데이터를 10만 건 정도 만들어서 테스트 서버에 넣으려고 하는데, 가짜 데이터라도 규제 대상인가요?",
    "answer": "가상의 데이터(Synthetic Data) 자체는 실존 인물 정보가 아니어 규제에서 자유로우나, 해당 데이터를 생성하는 프롬프트에 실존 유저의 원본 데이터를 마스킹 없이 입력했다면 개인정보 유출 리스크가 발생합니다. 원본 데이터를 활용해 가짜 데이터를 증폭시켰는지 생성 과정을 확인해 주시면 정확한 답변을 드리겠습니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법 적용 범위 및 유럽 인공지능법(EU AI Act) 제2조."
  },
  {
    "question": "자체 개발한 X-ray 판독 보조 AI 솔루션을 유럽 병원에 납품하려고 합니다. 서버는 한국에 두고 API로만 결과를 전송할 건데, 규제를 똑같이 받나요?",
    "answer": "서버의 물리적 위치와 무관하게 시스템의 결과물이 유럽에서 사용될 경우 고위험 AI 요건이 전면 적용되며, 의료기기 인증(CE) 및 인적 감독 조치를 누락하면 납품 취소 및 의료 사고 시 징벌적 손해배상 리스크가 발생합니다. 현지 의사가 최종 판단을 번복할 수 있는 인터페이스가 구현되어 있는지 추가로 확인해야 합니다. 한국에서 개발되어 유럽 현지로 결과를 전송하는 건이므로 유럽 인공지능법(EU AI Act) 위주로 답변드립니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 제6조 및 부속서 2에 따라 관련 안전 법률이 적용되는 고위험 AI에 해당합니다.\n- 핵심 의무: 제2조에 따라 서버 위치와 관계없이 법의 통제를 받으며, 유럽 내 배포 전 CE 마크 획득을 위한 적합성 평가를 받아야 하고 제14조에 따른 인적 감독 체계를 설계해야 합니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제2조(적용 범위), 제6조(고위험 시스템 분류 규칙), 제14조(인적 감독)."
  },
  {
    "question": "개발팀 생산성 높이려고 코파일럿 같은 AI 코딩 툴을 전사적으로 도입하려고 합니다. 주의할 점이 있을까요?",
    "answer": "코딩 보조 도구는 규제상 고위험 시스템에 속하지 않으나, 직원들이 작성 중인 회사의 핵심 소스 코드가 외부 AI 모델의 학습 데이터로 재활용(Opt-in)되어 유출될 위험성이 존재합니다. 엔터프라이즈 버전을 사용하여 데이터 외부 전송을 차단했는지 계약 조건을 확인하시고, 유럽 인공지능법(EU AI Act) 제50조에 근거하여 AI 기술을 활용 중임을 사내에 안내해야 합니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "유럽 진출을 위해 대체 데이터(SNS 활동, 통신비 납부 이력 등)를 활용하여 사용자의 신용 등급을 평가하고 대출 한도를 산정하는 딥러닝 모델을 개발하고 있습니다.",
    "answer": "신용 점수 산정 모델은 특정 집단에 대한 알고리즘 차별이 발생할 경우 투명성 및 데이터 거버넌스 위반으로 간주되어 서비스 중단 및 거액의 과징금을 유발하는 매우 엄격한 통제 분야입니다. 학습된 모델이 나이나 성별에 따라 승인 거절 비율이 치우치지 않는지 편향성 테스트를 정기적으로 수행하는 로직이 내재화되어 있는지 점검해야 합니다. 유럽 진출 목적이므로 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 부속서 3에 명시된 '필수 민간 서비스 및 공공 서비스(신용 점수 산정)' 관련 고위험 AI로 명확히 분류됩니다.\n- 핵심 의무: 제11조에 따라 의사결정 과정을 설명할 수 있는 상세한 기술 문서를 작성해야 하며, 제10조에 근거하여 학습 데이터 내 편향성이 없음을 입증하는 기록을 유지해야 합니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제10조(데이터 거버넌스), 제11조(기술 문서 작성), 부속서 3."
  },
  {
    "question": "저희 서비스에 외부 날씨 분석 AI API를 연동해서 날씨에 맞는 옷차림을 추천해 주는 기능을 넣으려는데 규제받나요?",
    "answer": "옷차림 추천 시스템은 사람의 기본권에 영향을 미치지 않아 고위험군 규제 대상에서 제외되어 기능 도입에 제약이 적습니다. 단, 날씨 분석을 위해 사용자의 GPS 위치 정보가 연동될 경우 동의 절차가 필요하며, 해당 추천 결과가 AI에 의해 도출되었음을 사용자 인터페이스에 명시할 것을 권장합니다. 연동 시 위치 데이터를 직접 수집하는지 확인해 주십시오. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "자율주행 로봇이 수집한 도로 상황과 보행자 영상 데이터를 클라우드에서 AI로 분석해 주행 경로를 업데이트하고 있습니다. 유럽 수출을 준비 중인데 법적 허들이 있나요?",
    "answer": "안전 부품으로 작동하는 AI 시스템의 경우, 분석된 데이터를 통해 주행 경로를 오판하거나 사이버 공격에 취약할 경우 인명 사고로 직결되므로 전면 리콜 및 막대한 과징금이라는 법적 허들이 존재합니다. 수집된 보행자 얼굴 영상이 즉각 비식별화 처리되는지, 그리고 클라우드와의 통신 암호화 수준이 기준을 충족하는지 반드시 사전 확인이 필요합니다. 유럽 수출 건이므로 유럽 인공지능법(EU AI Act)에 입각하여 답변드립니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 제6조 및 부속서 2에 따라 관련 조화 법률이 적용되는 고위험 AI에 해당합니다.\n- 핵심 의무: 제15조에 규정된 바에 따라 시스템의 정확성, 견고성 및 사이버 보안 수준을 입증해야 합니다. 이 요건을 충족하지 못하면 수출이 불가능합니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제6조(고위험 시스템 분류), 제15조(정확성, 견고성 및 사이버 보안), 부속서 2."
  },
  {
    "question": "디자인팀에서 미드저니 같은 생성형 AI로 만든 일러스트를 서비스 메인 화면이랑 광고 배너에 그대로 쓰려고 하는데, 법적 문제가 있을까요?",
    "answer": "상업적 광고 이미지로 활용할 때, 해당 일러스트가 특정 유명 작가의 화풍을 모방하거나 상표권이 있는 요소를 무단 포함하도록 프롬프트가 설정되었다면 저작권 침해 소지가 발생합니다. 프롬프트 작성 시 타인의 저작물을 참조했는지 확인이 필요하며, 사용된 배포물 하단에 생성형 AI 산출물임을 고지하여 투명성 의무를 준수해야 합니다. 질문에 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "해외 유명 배우의 얼굴과 목소리를 AI로 합성(딥페이크)하여 유럽 현지 맞춤형 프로모션 영상을 제작하려고 합니다. 모델 에이전시와 초상권 계약은 맺은 상태입니다.",
    "answer": "초상권 계약을 맺었더라도 딥페이크 기술로 조작된 영상임을 시청자가 즉각 인지하도록 조치하지 않으면, 투명성 의무 위반으로 간주되어 최대 500만 유로의 과징금이 부과되는 명백한 규제 리스크가 존재합니다. 영상의 도입부나 워터마크를 통해 AI 합성 사실이 명확하게 표기되는 프로세스가 기획안에 포함되었는지 확인해야 합니다. 유럽 현지 프로모션 목적이므로 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 제50조에 명시된 딥페이크 시스템에 해당합니다.\n- 핵심 의무: 제50조에 따라 배포자는 해당 영상이나 음성이 조작되었다는 사실을 사용자가 쉽게 인지할 수 있도록 명확하게 워터마크나 자막으로 고지해야 하는 법적 의무가 있습니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(특정 AI 시스템에 대한 투명성 의무)."
  },
  {
    "question": "마케팅팀에서 AI를 이용해서 고객 구매 이력을 분석한 다음, 개인별 맞춤형 광고 메일을 자동으로 발송하려고 합니다. 문제 될 만한 게 있을까요?",
    "answer": "구매 이력 기반의 이메일 타겟팅은 고위험 시스템으로 분류되지 않으나, 사용자의 사전 동의 없이 무단으로 취향을 프로파일링하여 스팸성 메일을 발송할 경우 개인정보보호법에 따른 리스크가 발생합니다. 고객 가입 단계에서 마케팅 수신 및 개인화된 혜택 제공에 대한 명시적 동의(Opt-in) 절차가 마련되어 있는지 확인이 필요하며, 타겟팅에 알고리즘이 쓰이고 있음을 안내해야 합니다. 질문에 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무) 및 개인정보 관련 지침 참고."
  },
  {
    "question": "유럽 소비자를 대상으로 인지하기 어려울 만큼 매우 짧은 컷(0.1초) 단위로 AI가 분석한 구매 자극 이미지를 광고 영상에 숨겨서 구매 전환율을 높이는 테스트를 하려 합니다.",
    "answer": "이 기획안은 소비자의 합리적 판단을 무의식중에 왜곡하는 '잠재의식 조작 기법'을 활용하는 것으로, 실행 시 시장 내 전면 금지 및 3,500만 유로에 달하는 최고 수준의 과징금이 부과되는 중대한 범법 행위이므로 즉시 폐기해야 합니다. 유사한 형태의 심리 자극을 목적에 두는 추가적인 광고 기획이 있는지 점검을 요합니다. 유럽 대상을 명시하셨으므로 유럽 인공지능법(EU AI Act)에 입각하여 답변드립니다.\n- 규제 대상: 사람의 의식을 우회하여 잠재의식 수준의 기술(Subliminal techniques)을 사용하는 행위는 유럽 인공지능법(EU AI Act) 제5조에 의해 금지된 인공지능 관행입니다.\n- 제재 사유: 제5조에 따르면, 개인의 합리적 판단을 실질적으로 왜곡하여 신체적 또는 정신적 피해를 유발할 가능성이 있는 시스템은 어떠한 경우에도 제공 및 사용이 전면 금지됩니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제5조(금지된 인공지능 관행)."
  },
  {
    "question": "저희 서비스 마스코트 캐릭터와 대화할 수 있는 귀여운 AI 챗봇을 만들었는데, 아이들도 많이 쓸 것 같습니다. 주의사항이 있나요?",
    "answer": "아동 대상 서비스일 경우, 챗봇이 아이들의 심리적 애착이나 연령적 취약성을 이용해 특정 제품의 인앱 결제를 유도하는 등 불합리한 행동을 촉발한다면 금지된 인공지능 관행으로 처벌받을 리스크가 높습니다. 챗봇의 응답 시나리오에 상업적 구매 유도나 유해한 콘텐츠가 필터링되는 안전망이 적용되어 있는지, 그리고 사용자가 AI와 대화 중임을 고지했는지 반드시 확인해 주시기 바랍니다. 질문에 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제5조(금지된 인공지능 관행), 제50조(투명성 의무)."
  },
  {
    "question": "유럽 각국 언어로 우리 제품 설명서와 법적 약관을 LLM이 자동 번역해서 배포하는 자동화 파이프라인을 구축했습니다. 검수는 시간이 부족해 생략하려 합니다.",
    "answer": "소비자의 권리와 직결되는 법적 약관의 자동 번역 결과를 무검수로 배포할 경우, 오역으로 인한 분쟁 발생 시 면책이 불가능하며 투명성 의무 위반에 따른 현지 소송 및 과징금 리스크에 노출됩니다. 문서 하단에 AI 생성물임을 고지함과 동시에, 최소한의 중요 조항에 대해서는 사람(현지어 전문가)이 내용을 검증할 수 있는 샘플링 검수 체계가 설계되어 있는지 파악해야 합니다. 유럽 현지화 전략이 포함되어 있으므로 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 규제 요건: 유럽 인공지능법(EU AI Act) 제50조에 따라 문서가 AI 모델에 의해 생성되거나 번역되었음을 명확히 고지할 법적 의무가 발생합니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "홍보 영상에 성우 섭외 비용이 비싸서, AI TTS(텍스트 음성 변환) 솔루션으로 내레이션을 입히려고 합니다. 문제없을까요?",
    "answer": "TTS 솔루션 도입 자체는 리스크가 낮으나, 해당 솔루션이 생성해 내는 음성이 합법적으로 권리가 확보되지 않은 특정 유명인의 목소리를 무단으로 합성한 것이라면 초상권 침해 문제가 생길 수 있습니다. 정식 라이선스를 취득한 상업용 솔루션인지 확인해 주시고, 영상 내에 해당 내레이션이 AI로 생성되었음을 안내하는 표기 계획이 있는지 점검이 필요합니다. 질문에 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(특정 시스템 투명성 의무)."
  },
  {
    "question": "고객의 현재 기분 상태를 텍스트로 분석한 뒤, 우울감을 느끼는 고객에게만 충동구매를 유도하는 맞춤형 광고 문구를 생성해 발송하는 알고리즘을 설계했습니다.",
    "answer": "고객의 심리적 취약성(우울감)을 데이터로 식별하여 이를 의도적으로 악용해 금전적 행위(충동구매)를 유도하는 방식은 명백히 금지된 AI 시스템에 해당하며, 적발 시 최대 3,500만 유로의 과징금이 부과되는 사업 존폐 리스크를 수반합니다. 타겟 마케팅 변수에서 개인의 감정이나 취약성 지표가 수집 활용되고 있는지 즉시 재검토 및 삭제 조치가 필요합니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 종합하여 답변드립니다.\n- 금지 조항: 유럽 인공지능법(EU AI Act) 제5조는 특정 사회적, 심리적 상황으로 인한 취약성을 악용하여 개인 행동을 실질적으로 왜곡하는 시스템을 금지하고 있습니다.\n- 규제 리스크: 이와 같은 행위는 한국의 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법의 신뢰성 원칙에도 정면으로 위배됩니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제5조(금지된 인공지능 관행)."
  },
  {
    "question": "쇼핑몰 메인 화면에 고객별로 자주 클릭하는 상품군을 AI가 예측해서 배너 순서를 다르게 보여주려고 합니다. 규제받나요?",
    "answer": "쇼핑몰의 일반적 상품 추천 기능은 고위험 AI에 속하지 않으므로 즉각적인 규제 허들이 낮습니다. 다만, 특정 조건에 따라 배너 추천 로직이 동작하고 있다는 사실을 명시해야 하며, 쇼핑몰의 규모가 현지 시장에서 초거대 플랫폼에 해당할 경우 알고리즘 추천 내역을 투명하게 보고해야 할 의무가 추가될 수 있으니 월간 활성 사용자 수에 대한 정보 확인이 필요합니다. 질문에 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "신제품 출시에 맞춰 수만 개의 AI 챗봇 계정을 활용해 트위터와 인스타그램에서 긍정적인 여론을 형성하고 특정 해시태그를 인기 순위에 올리는 마케팅을 기획 중입니다.",
    "answer": "진짜 사람인 것처럼 위장하여 여론을 조작하는 AI 봇 운용은 투명성 의무를 전면적으로 위반하는 행위이며, 적발 시 플랫폼 영구 퇴출은 물론 최대 500만 유로의 과징금이 부과될 수 있는 리스크가 있습니다. 계정이 AI임을 명백히 알 수 있도록 아이디나 프로필에 고지할 방침인지 확인이 필수적이나, 조작 목적의 기획이므로 기획안 수정을 권고합니다. 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 핵심 의무: 사람과 소통하는 AI 시스템(챗봇)은 자신이 AI라는 사실을 상대방이 명확히 알 수 있도록 설계되어야 하는 투명성 의무가 유럽 인공지능법(EU AI Act) 제50조에 강력히 규정되어 있습니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(특정 시스템 투명성 의무)."
  },
  {
    "question": "자사 웹사이트에 고객의 환불이나 배송 문의를 자동으로 처리해 주는 AI 상담 챗봇을 도입해서 다음 달에 오픈하려고 합니다. 법적인 이슈가 있을까요?",
    "answer": "고객 응대용 챗봇은 일반 위험 등급이므로 서비스 출시에 큰 걸림돌은 없으나, 자연인과 대화하는 시스템임에도 자신이 AI임을 밝히지 않으면 투명성 의무 위반에 해당합니다. 서비스 접속 화면이나 대화창에 \"AI 상담사와 연결되었습니다\"라는 안내 문구가 시스템적으로 고정되어 노출되는지 최종 런칭 전 점검해 주시기 바랍니다. 질문에 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "스마트폰 카메라로 피부 병변을 찍으면 피부암 확률을 계산해 주는 AI 앱을 유럽 앱스토어에 출시하려 합니다. 유럽에서 요구하는 인증 절차가 어떻게 되나요?",
    "answer": "의료 데이터를 바탕으로 진단 확률을 계산하는 시스템은 인명 피해로 직결될 수 있는 초고위험 분야이므로, 제3자 인증 기관의 적합성 평가(CE 마크 획득)를 누락하고 출시할 경우 강제 서비스 종료 처분 및 1,500만 유로 상당의 과징금을 맞게 됩니다. 현지 의료 기기 규제 요건에 맞춘 시판 후 모니터링 체계와 임상 평가 보고서가 준비되었는지 상세한 점검이 필요합니다. 유럽 내 출시이므로 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 규제 대상: 인명 및 건강에 영향을 미치는 시스템으로, 유럽 인공지능법(EU AI Act) 부속서 2 및 의료 관련 조화 법률에 따라 명백한 고위험 AI로 분류됩니다.\n- 핵심 의무: 제43조에 따라 제3자 인증 기관을 통한 적합성 평가 절차를 반드시 거쳐야 유럽 시장 출시가 가능합니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제43조(적합성 평가 절차), 부속서 2."
  },
  {
    "question": "사용자가 입력한 한국어 문서를 영어로 다듬어주는 AI 첨삭 기능을 구독형 서비스로 론칭하려는데, 규제 이슈가 큰가요?",
    "answer": "언어 번역 및 문법 교정 서비스는 기본권에 침해를 주지 않는 최소 위험군이라 규제 이슈가 크지 않습니다. 다만, 사용자가 번역기에 입력하는 민감한 개인 문서가 AI 모델의 학습에 재사용(Opt-in)되어 타인에게 노출될 위험이 있으므로, 데이터 수집 정책을 어떻게 설정하셨는지 확인이 필요하며 번역 결과물에 대한 AI 생성 고지가 권장됩니다. 질문에 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "유럽 현지 대학교에 수출할 목적으로, 학생들의 내신 성적과 생활기록부를 분석하여 입학 합격/불합격을 추천해 주는 AI 시스템을 개발 완료했습니다. 납품 전 필수 점검 항목이 궁금합니다.",
    "answer": "학업 성취도를 기반으로 입학 여부를 추천하는 모델은 학생의 인생에 결정적 영향을 미치므로, 인종이나 성별 등에 따른 알고리즘 편향성을 입증하지 못하거나 데이터베이스 의무 등록을 누락하면 수출 불가 및 벌금 대상이 되는 심각한 리스크가 존재합니다. 모델 훈련에 사용된 데이터가 입학 사정의 공정성을 담보할 수 있는지에 대한 자체 평가 문서(기술 문서)가 완비되어 있는지 확인해야 합니다. 유럽 현지 대학교 대상이므로 유럽 인공지능법(EU AI Act)에 의거하여 답변드립니다.\n- 규제 대상: 합격/불합격을 평가하는 시스템은 유럽 인공지능법(EU AI Act) 부속서 3에 명시된 교육 및 직업 훈련 영역의 고위험 AI에 해당합니다.\n- 핵심 의무: 제51조에 근거하여 제공자는 해당 시스템의 설계 정보 등을 의무적으로 관련 데이터베이스에 사전 등록해야 합니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제51조(등록 의무), 부속서 3."
  },
  {
    "question": "직장인들 스케줄 관리해주고 회의록 요약해 주는 AI 비서 앱을 기획 중인데, 캘린더나 이메일 연동 관련해서 특별한 AI 규제가 있을까요?",
    "answer": "개인 비서 솔루션은 고위험 AI에 속하지 않으나, 타인의 메일 내용이나 일정 등 사생활과 밀접한 정보를 다루기 때문에 데이터 유출 방지가 가장 핵심적인 리스크 관리 항목입니다. 요약 처리가 기기 내부(On-device)에서 진행되는지 혹은 클라우드 서버로 전송되는지 기술적 방식을 확인해 주시고, 챗봇과 소통 시 AI임을 알리는 투명성 기능 삽입을 검토해야 합니다. 질문에 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "다양한 텍스트와 이미지 생성 작업이 가능한 자체 개발 범용 대형언어모델(GPAI) 기반 B2B 플랫폼을 유럽 시장에 본격 출시하려고 합니다.",
    "answer": "자체 개발한 범용 대형언어모델을 유럽에 직접 배포할 경우 가장 무거운 시스템적 규제가 적용되며, 학습 데이터에 대한 저작권 요건을 준수하지 못하거나 적대적 공격 테스트를 거치지 않으면 매출의 3%에 달하는 벌금이 부과되는 중대 리스크를 떠안게 됩니다. 모델의 누적 학습 연산량(FLOPs)이 유럽 인공지능법이 규정한 시스템적 위험 기준치(10^25)를 초과하는 규모인지 우선적으로 파악해 주시기 바랍니다. 유럽 시장 진출 건이므로 유럽 인공지능법(EU AI Act)을 적용하여 답변드립니다.\n- 핵심 의무: 자체 개발한 범용 AI 모델을 시장에 내놓는 제공자는 유럽 인공지능법(EU AI Act) 제53조에 따라 모델 아키텍처에 대한 문서화, 학습 데이터 요약본 제공 등의 법적 의무를 철저히 이행해야 합니다.\n- 제재 규정: 투명성 조치 및 기타 제약 요건을 위반할 경우 제71조에 따라 매우 강도 높은 벌금이 부과될 수 있습니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제53조(범용 AI 제공자 의무), 제71조(벌칙)."
  },
  {
    "question": "사용자가 허밍으로 멜로디를 부르면 AI가 3분짜리 곡으로 완성해 주는 앱을 만들었습니다. 수익 창출 구조를 붙여서 출시하려는데 문제없겠죠?",
    "answer": "작곡 앱은 위험 등급이 낮아 규제 제약이 크지 않지만, 생성된 결과물이 타인의 지식재산권을 침해할 가능성 및 투명성 조치 위반 리스크가 존재합니다. 앱을 통해 생성된 오디오 파일에 해당 곡이 인위적으로 생성된 AI 저작물임을 암호화된 워터마크나 파일 메타데이터 형태로 명시하는 로직이 개발되어 있는지 추가 확인이 필요합니다. 질문에 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "유럽 매장에서 별도 카드 없이 기기에 홍채만 인식시키면 고객 계좌에서 밥값이 자동 결제되는 AI 결제 시스템을 론칭하려고 합니다.",
    "answer": "결제와 연동되는 실시간 생체(홍채) 인증 시스템은 해킹 등 사이버 공격에 의해 생체 데이터가 유출될 경우 복구 불가능한 재산 피해를 낳기 때문에, 최고 수준의 사이버 보안 요건을 증명하지 못하면 유럽 내 서비스가 불가능하고 대규모 과징금이 유발됩니다. 수집된 홍채 정보가 서버에 중앙 집중형으로 저장되는지 혹은 기기 보안 영역(TrustZone)에서 암호화되어 로컬 매칭되는지 아키텍처 점검이 요구됩니다. 유럽 서비스 도입 건이므로 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 부속서 3에 명시된 원격 생체인식 시스템에 포함되어 고위험 AI로 취급됩니다.\n- 핵심 의무: 생체 정보의 특성상 사이버 위협에 매우 취약하므로, 제15조에 규정된 시스템의 보안성 및 정확성 기준을 명백하게 증명하는 문서를 구비해야 합니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제15조(정확성 및 사이버 보안), 부속서 3."
  },
  {
    "question": "저희가 개발 중인 롤플레잉 게임 안에 유저 질문에 스스로 대답하는 딥러닝 기반 AI NPC를 여러 마리 넣을 건데 법 검토를 해야 할까요?",
    "answer": "게임용 NPC는 안전한 용도로 간주되어 복잡한 규제 등록을 거칠 필요는 없으나, 대화 주체가 실제 사람이 아닌 AI임을 밝히지 않으면 투명성 의무 위반에 해당할 수 있습니다. 해당 NPC와 상호작용할 때 유저 인터페이스(UI)나 게임 내 대화창에 AI 구동 표시가 시각적으로 적용되어 있는지 확인만 해주시면 문제없이 출시가 가능합니다. 질문에 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "유럽 현지 구급차 서비스 센터에, 신고자의 목소리와 심장 박동 등 생체 신호를 AI가 분석해서 출동 우선순위(Triage)를 정하는 시스템을 납품하려 합니다.",
    "answer": "인명 구조와 직접 연결되는 응급 배차 시스템은 시스템 오작동 시 사망 사고 등 돌이킬 수 없는 피해를 발생시키므로, 사람이 최종 개입하여 시스템의 지시를 재검토할 수 있는 설계 구조(인적 감독)를 누락하면 납품 자체가 위법이 됩니다. 긴급 상황에서 훈련된 요원이 AI의 배차 지시를 무시(Override)하고 직접 권한을 행사할 수 있는 백도어 기능이 구현되어 있는지 확인해야 합니다. 유럽 관할 공공 서비스 목적이므로 유럽 인공지능법(EU AI Act)에 근거하여 답변드립니다.\n- 규제 대상: 유럽 인공지능법(EU AI Act) 부속서 3에 명시된 필수 공공 서비스 영역의 응급 구호 응답 관련 고위험 AI에 정확히 부합합니다.\n- 핵심 의무: 응급 배차 등 인명과 직결된 판단은 오류 시 심각한 결과를 낳으므로, 제11조에 따른 기술 문서 작성뿐 아니라 제14조에 따라 훈련 요원이 개입하여 최종 결정을 내리거나 AI 지시를 무시할 수 있는 인적 감독 조치가 법적으로 의무화되어 있습니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제11조(기술 문서 작성), 제14조(인적 감독), 부속서 3."
  },
  {
    "question": "우리 회사가 이번에 전사적으로 오픈AI나 구글 같은 거대 AI 모델을 도입해서 업무 효율을 높인다는데, 임원으로서 회사 차원의 법적 리스크가 없는지 챙겨봐야 할 게 뭐가 있습니까?",
    "answer": "타사 모델을 사내에 도입하는 배포자(Deployer) 입장이더라도, 임직원이 모델을 활용해 생성한 산출물을 외부 고객에게 발송하거나 공표할 때 AI 생성물임을 명시하지 않으면 회사가 투명성 위반 책임을 지게 되며, 기밀 데이터를 입력할 경우 정보 유출 리스크가 따릅니다. 사내에 'AI 활용 지침'이 배포되었는지, 도입된 시스템이 기업용 비학습 데이터 옵션을 켜두었는지 확인이 필요합니다. 질문에 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 종합하여 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "우리가 유럽에 수출하는 AI 공정 제어 솔루션이 만약 고위험 AI 규정을 위반하게 된다면 회사 매출액 기준으로 벌금이 얼마나 나오는지, 대응 TF는 어떻게 꾸려야 하는지 명확히 알고 싶습니다.",
    "answer": "수출입 과정에서 고위험 AI 요건을 의도적으로 회피하거나 적합성 평가를 이행하지 않을 경우 기업 재무에 치명적인 타격을 주는 수백억 원대 과징금 부과 대상이 되며, 거짓 정보를 제공할 경우 추가 벌금이 부과되는 중대 리스크가 존재합니다. 현재 개발 부서에서 품질 관리 프로세스를 정기적으로 문서화하고 있는지, 그리고 법무팀과 연계된 전담 TF가 꾸려져 있는지 조속한 확인이 필요합니다. 유럽 수출 통제 대상 시스템이므로 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 위반 리스크: 유럽 인공지능법(EU AI Act) 제71조에 따르면 고위험 AI의 요건을 중대하게 위반할 경우, 귀사는 최대 1,500만 유로 또는 글로벌 연 매출의 3% 중 더 큰 금액의 과징금을 부과받을 법적 책임을 집니다. 문서 허위 제출 시 제재 조항이 별도로 존재하므로 철저한 사전 적합성 평가에 집중해야 합니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제71조(벌칙)."
  },
  {
    "question": "유럽법이 까다롭다니까 AI 모델 개발과 학습을 규제가 느슨한 동남아 자회사에 외주로 맡겨서 완성품만 수입해서 유럽에 납품하려고 합니다. 규제를 피할 수 있겠죠?",
    "answer": "해외 자회사에서 개발하더라도 그 시스템이나 결과물이 최종적으로 통제 영역(유럽 시장 등)에 진입하게 되면 현지 법령이 역외 적용되므로, 규제를 피하기 위한 외주 개발 꼼수는 전면 판매 금지와 제재로 귀결되는 치명적 리스크를 안고 있습니다. 자회사가 개발 단계에서부터 데이터 품질과 알고리즘 편향성 제어 기준을 준수하고 있는지 관리 체계를 확인해야 합니다. 동남아시아의 경우 관련 인공지능 법령이 만들어져서 시행되지는 않았을 수 있으나, 최종 수출처가 유럽이므로 유럽 인공지능법(EU AI Act) 및 기준으로 활용되는 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법에 의거하여 답변드립니다.\n- 핵심 논리: 유럽 인공지능법(EU AI Act) 제2조(적용 범위)에 따라 AI 시스템을 실제로 개발한 장소와 무관하게, 그 출력 결과물이나 시스템이 유럽 연합 내에 공급되는 순간 해당 법률이 100% 동일하게 적용됩니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제2조(적용 범위)."
  },
  {
    "question": "한국 본사에만 조직이 있고 유럽 현지에는 지사나 법인이 전혀 없습니다. 유럽 유저들이 우리 플랫폼의 AI 기능을 많이 쓰는데, 현지에 법인이 없어도 규제 대응을 해야 합니까?",
    "answer": "서비스 타겟 지역 내에 물리적 법인이 없더라도 해당 서비스를 제공하는 것 자체로 규정 준수 의무가 강제되며, 공인 대리인을 지정하지 않으면 현지 서비스 배포 금지 및 과징금 리스크가 즉각적으로 발생합니다. 회사가 공식 서면을 통해 법적 소통 창구 역할을 할 공인 대리인을 물색하고 계약할 계획이 있는지 시급하게 확인을 권장합니다. 한국 기업이 유럽 유저를 대상으로 서비스하는 건이므로 양국 법률, 특히 역외 적용이 명시된 유럽 인공지능법(EU AI Act)을 토대로 답변드립니다.\n- 핵심 의무: 현지 법인 유무와는 관계없이 규제가 강제됩니다. 유럽 인공지능법(EU AI Act) 제22조에 따르면, 유럽 역내에 설립되지 않은 기업이 유럽 시장에 AI 시스템을 제공할 경우 반드시 서면으로 공인 대리인(Authorised Representative)을 역내에 지정해야 할 법적 의무가 있습니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제22조(공인 대리인 지정)."
  },
  {
    "question": "외부에서 사 온 AI 솔루션을 조금만 우리 회사 색깔에 맞춰 파인튜닝해서, 마치 우리가 직접 만든 솔루션인 것처럼 브랜드 이름을 달고 팔아도 법적으로 우리 책임은 아닌 거죠?",
    "answer": "타사 솔루션에 자사 브랜드를 붙여 시장에 배포하는 순간 원천 개발자의 법적 책임이 귀사로 이전되므로, 품질 인증과 투명성 조치를 직접 이행하지 않을 경우 회사가 규제 당국의 과징금 처분 타겟이 되는 엄중한 리스크가 발생합니다. 사오신 원본 AI 솔루션이 이미 필요한 적합성 인증을 모두 취득한 상태인지, 벤더사와의 법적 책임 한계가 계약서에 명시되어 있는지 필히 확인해야 합니다. 국가가 특정되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법 제24조(신뢰성 확보 조치), 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "당사가 유럽 은행에 공급한 자금 세탁 탐지 AI(고위험)가 외부 해킹 공격을 받아 고객 계좌 정보가 유출되고 오작동하는 사고가 발생했습니다. 회사 차원에서 당장 어떤 조치를 취해야 벌금을 최소화할 수 있습니까?",
    "answer": "중대한 시스템 오작동 및 데이터 유출 사고 발생 시 관할 당국에 15일 이내 보고 의무를 이행하지 않으면 정보 은폐로 간주되어 과징금이 가중 부과되는 가장 높은 수준의 위기 상황입니다. 즉각적인 시스템 차단 및 현장 조사 지시가 내려졌는지 확인하시고, 피해 구제와 보고 절차를 진행할 비상 대책 위원회 소집 현황을 파악해야 합니다. 유럽 금융기관 납품 건이므로 관련 규제인 유럽 인공지능법(EU AI Act)에 입각하여 안내해 드립니다.\n- 핵심 의무: 유럽 인공지능법(EU AI Act) 제62조에 따라, 시스템이 중대한 위험이나 오작동을 초래했음을 인지한 시점으로부터 최대 15일 이내에 관할 당국에 사실을 보고할 의무가 존재합니다.\n- 위반 리스크: 이 보고 의무를 지연하거나 은폐할 경우 제71조에 따른 과징금 가중 처벌 요인이 됩니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제62조(중대한 사건 및 오작동 보고), 제71조(벌칙)."
  },
  {
    "question": "직원들이 AI 쓰다가 회사 기밀 유출할까 봐 겁나는데, 회사에서 \"회사 내의 모든 행동은 AI를 통해 감시/분석될 수 있다\"고 공지만 띄우면 규제 프리패스인가요?",
    "answer": "단순 사내 공지문 작성만으로는 시스템이 유발하는 기본권 침해 및 투명성 위반 책임을 회피할 수 없으며, 감시 목적이 인사 평가와 연동될 경우 고위험 AI 수준의 엄격한 요건을 준수하지 않을 시 노동법과 인공지능 법안에 모두 저촉되는 리스크가 큽니다. 실제로 사내 AI가 어떤 범위의 직원 데이터를 수집하고 이를 자동화된 인사 평가 로직에 반영하고 있는지 상세히 검토해야 합니다. 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 기준으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "우리 회사의 신기술 AI 모델이 현재 규제 기준을 초과할 것 같은데, 규제를 잠시 면제받고 테스트해 볼 수 있는 유럽 내 합법적인 제도가 존재합니까? 임원진 보고용으로 정리 부탁드립니다.",
    "answer": "규제 샌드박스를 통해 신기술을 출시 전에 검증할 수 있는 통로가 마련되어 있으나, 샌드박스 진입 자체가 향후 상용화 시 고위험 AI 적합성 평가 의무를 완전히 소멸시키는 면죄부는 아니므로 상용화 시점의 인증 지연 리스크를 함께 고려해야 합니다. 자사 모델의 신기술 요소가 당국이 인정하는 공익적 목적(환경, 보건 등)에 부합하여 샌드박스 지원 자격을 갖추고 있는지 확인이 선행되어야 합니다. 유럽 시장 제도 문의 건이므로 유럽 인공지능법(EU AI Act)을 바탕으로 답변드립니다.\n- 활용 방안: 유럽 인공지능법(EU AI Act) 제57조에 따라 AI 규제 샌드박스(Regulatory Sandbox) 제도가 공식적으로 지원됩니다.\n- 조건: 법안에 따라 통제된 환경에서 출시 전 사전 검증을 받을 수 있으나, 이 제도 자체가 고위험 시스템의 의무 요건을 영구적으로 면제하는 것은 아닙니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제57조 및 제58조(AI 규제 샌드박스)."
  },
  {
    "question": "우리 회사의 광고 AI 툴이 다른 회사의 로고를 비슷하게 베껴서 결과물을 냈고, 그걸 담당 직원이 그대로 광고에 써서 내용증명을 받았습니다. 책임은 AI 솔루션을 만든 제공자에게 있는 거 아닙니까?",
    "answer": "직원이 자사 광고 업무에 타 솔루션을 이용한 결과물을 그대로 외부에 공표한 이상, 생성된 이미지가 AI를 기반으로 제작되었음을 명시하지 않은 투명성 위반 책임과 저작권 침해 방조 책임이 배포자인 귀사에 직접적으로 부여됩니다. 귀사가 AI 툴 벤더사와 맺은 이용 계약에 산출물의 저작권 분쟁 시 배상 조항이 포함되어 있는지 법무팀을 통해 확인해야 합니다. 특정 국가가 명시되지 않아 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)을 바탕으로 답변드립니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제50조(투명성 의무)."
  },
  {
    "question": "특정 국가 정부의 요청으로, 시민들의 신용 정보, 범죄 이력, 온라인 활동을 종합해 사회적 신용 등급을 매기고 복지 혜택을 차등 지급하는 AI 시스템 개발 수주를 제안받았습니다. 유럽이 아닌 국가에 납품하는 건데 프로젝트를 진행해도 될까요?",
    "answer": "소셜 스코어링 시스템 개발은 납품 국가와 무관하게 글로벌 인권 기준 및 인공지능 법안의 근본 원칙을 훼손하는 명백한 금지 관행으로, 프로젝트 진행 시 추후 선진국 및 유럽 시장 진출 전면 차단이라는 회복 불능의 사업적 리스크를 초래하므로 절대 수주해서는 안 됩니다. 해당 제안서의 다른 영역(일반 전산화 등)으로 사업 범위를 완전히 변경할 수 있는지 확인이 필요합니다. 제안받으신 국가는 현재 명확하게 시행 중인 인공지능 관련 법령이 만들어져서 시행되지는 않았을 수 있으나, 글로벌 기준이 되는 인공지능 발전과 신뢰 기반 조성 등에 관한 기본법과 유럽 인공지능법(EU AI Act)에 따라 답변드립니다.\n- 규제 상황: 여러 데이터를 종합해 시민을 평가하고 불이익을 유발하는 소셜 스코어링 모델은 유럽 인공지능법(EU AI Act) 제5조에 의해 어떠한 이유로도 타협 불가능한 금지된 인공지능 관행입니다.\n- 리스크 검토: 납품처가 비유럽 국가라도 글로벌 무역 시장에서 금지된 AI 시스템 수주는 치명적 위법 리스크를 동반하므로 수주를 강력히 반려할 것을 권고합니다.\n- 근거 조항: 유럽 인공지능법(EU AI Act) 제5조(금지된 인공지능 관행)."
  }
]